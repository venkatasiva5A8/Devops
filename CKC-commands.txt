pidof java 
 pwdx <processid>  //process to check java
 
 
 topmonitor Cluster_Name (Ex: stopmonitor KCMO) //stopping the monitor
 
 tql -cluster -stop clusterid=Petrol_Cluster,instance=DE_SB_ParkingWorldSensing   //stop the process
 
 
  tql -cluster -stop clusterid=Petrol_Cluster,instance=DE_SB_ParkingWorldSensing  //stop the process
 
 /opt/cdpdeployment/monitor/cluster_files. 
 
 
 
 central configuratior machine 1=====>cluster details all services---mon
 
 
 -----------------------------------------
 1st machine ====northbound---system--device engine---(common)
 
 2nd ----device engine,extension engine with respect to providers and domains(parking)machine
 
 3rd -------------(light)machine


scp aws-produs-v4-devengine-victoria-1:/tmp/local ~/Desktop/ //copy to local

-------------------------------------------------------------------
login to machine 2

screen -r command '

Control+c===process stopped'

come back screen -r ''

start command by using up arrow

control A + D
----------------------------------------------------------------------------------
/opt/cdpdeployment/configuratorDaemon/resources/atomiton/configurator/spaces/scripts //configurator.log path



CKC LVL2 phone numbers

Shaheer Hassan --- +91 9886425222
Mohit Srivastva --- +91 7022707180
Shaik Basha --- +91 8217768165
Rakesh --- +91 9686240238
Raghav Haribal --- +91 7799371000
Mohammad Farhan --- +91 9807876151
Ritesh Singh --- +91 89500 45982
Abhishek Bansal --- +91 9811963651
Anusha Gnv --- +91 8046202936
Manivannan Radhakrishnan --- +91 7760093627

Srinivasan Krishna Kumar-Cisco --- +91 9008026950
Thirumalesh Palleri -Cisco --- +91 9886089593
========================================================================
tql -cluster -stop clusterid=Berlin_Cluster,instance=DE_NorthBound
Manivannan Radhakrishnan 12:08 PM
statuscluster KCMO
Manivannan Radhakrishnan 12:23 PM
find . -name "*.hprof"
-------------------------------------------------------------------------------------------------
Cluster Monitoring :

First need to check which process getting failed by seeing the Cluster Monitoring dashboard

Then login to that VM and check any hprof files there are not.If there is any big hprof file , that we need to delete. before deletion we need to do follwing steps.

--> take logs backup of that particular process(make a copy in local desktop and need to raise CDET ticket(need to send to dev team))

--> Then we need to login to Central monitor machine(one per each reagion )(even here can find ip details where that process in that json file of particular tenant)

--> Stop the monitor process (command : stopmonitor)
--> Pause the cluster in API sciecne monitor dashboard(Need to check with Shaheer)
--> Stop the process using the command : tql -cluster -stop clusterid=Berlin_Cluster,instance=DE_NorthBound
--> Delete the hprof files in that machine
--> Start the process using the command : tql -cluster -start clusterid=Berlin_Cluster,instance=DE_NorthBound
--> Start the Cluster in the API Sceience monitor dashboard(Need to check with Shaheer)
--> Start the monitor the process (Command : startmonitor)

--> primarily we need to anaylyze the log.

Note: stop the cluster command : stopcluster Tenant_name (all the process will be stopped and always check the alias names in bashrc_profile))
----------------------------------------------------------------------------------------------------------------------------------
de
cd opt/
cat extension.log >filename
chmod 644 filename
mv filename /tmp/
scp aws-prodemea-v4-devengine-reykjavik-2:/tmp/filename ~/Desktop/
==========================================

sudo shutdown -h now //shut down the machine
sudo shutdown -r now //restart the macine

pidof java|xargs pwdx  //

kill -9 "Pid of CD"//
tqlstart
sudo lsof | grep deleted  //

=============================================================
tql -cluster -stop clusterid=Reykjavik_Cluster,instance=DE_System

tql -cluster -start clusterid=Reykjavik_Cluster,instance=DE_System



stopmonitor Reykjavik
tql -cluster -stop clusterid=Reykjavik_Cluster,instance=DE_System
(Verify in DE machine that System process has been killed)
startcluster Reykjavik ("startcluster" will start up any stopped processes. Your start command is also correct)
(Verify in DE machine that System process in running, and tail the logs to see if any errors)
startmonitor Reykjavik
statuscluster Reykjavik (to confirm that all processes are running)
Login to Reyjavik dashboard and do a sanity check for all configured domains.


 ps -O etime -p 18414 //
 
 lsof |grep deleted
===================================================================================
tail -n 100000 slapd.log >> /tmp/temp_slapd.log
ll /tmp/temp_slapd.log
mv /tmp/temp_slapd.log slapd.log                 //purging the logs of full log to less mb
=============================================================================================
How to start/stop ConfiguratorDaemon process:
ssh into respective deviceEngine machine and login as "deviceEngine" user

For stop the configuratorDaemon process:
 
tql -engine -stop
 
For start the configuratorDaemon process:
 
tql -engine -start

3.04.30.5 How to start/stop MD process:
ssh into respective deviceconfigurator(Monitor) machine and login as "monitor" user

For stop the MD process:
 
tql -engine -stop
 
For start the MD process:
 
tql -engine -start
-------------------------------------------------------
tail -n 10000 /var/log/daemon.log. >. /tmp/temp-daemon.log cat /temp-daemon.log  >  /var/log/daemon.log We are keeping last 10000 lines of data rm /tmp/tmp-daemon.log

==========================================================
sudo du -a / 2>/dev/null | sort -n -r | head -n 20  //top 20 files occuping space

--------------------------------
tail -n 1000 configurator.log >> /tmp/temp_configurator.log
ll /tmp/temp_configurator.log
mv /tmp/temp_configurator.log configurator.log 
================================================

stopmonitor Erie

tql -cluster -stop clusterid=Erie_Cluster,instance=DE_System

tql -cluster -start clusterid=Erie_Cluster,instance=DE_System

startmonitor Erie
==========================================
find . -iname "http*" -type f -mtime +60
=====================================================
curl -k -X POST \
https://localhost:8080/fid-CIMUserQueryInterface \
-H 'AccessKey: CDP-App' \
-H 'Cache-Control: no-cache' \
-H 'Content-Type: application/json' \
-H 'cache-control: no-cache' \
-d '{ "Query": { "Find": { "ParkingSpace": { "sid": { "ne": "" } } } } }'

===========================================================================
find . -iname "*.hprof"
screen -ls
screen -r SCREENPID
screen -S screenname ----> to create a new screen
screen -S -X SCREENPID quit ------> to delete the screen
==============================================================
du -hs * | sort -rh | head -5          //top 5 files occupied space

zip -r /tmp/ProdUS-13DEC2019-APIGW-2.zip wso2carbon.log wso2carbon.log.1 wso2carbon.log.2 wso2carbon.log.3 wso2carbon.log.4

=================================================================================================================
systemctl status wso2  // Apigw ,Idmgw restart
systemctl start wso2

sudo service wso2
==============================================================================
opt/cdpdeployment/deviceEngine_FCS/deviceEngine_ParkingWorldSensing/worldsensing_java/resources
iptables -I INPUT -p tcp -s 10.126.0.0/16--dport 8080 -j ACCEPT                                  //changing port 8080
iptables-save
=============================================================================
curl http://localhost:8080/<health_check endpoint>
====================================================================
systemctl start httpd24-httpd //check the status of service
========================================================================
find . -iname "*" -mtime +45
=================================================
alias config="cd /opt/cdpdeployment/monitor/cluster_files"
alias disk="du -Sh | sort -rh | head -5"
alias provider="cd /opt/cdpdeployment/DevEngMonitoring"
alias tqlstop="tql -engine -stop"
alias tqlstart="tql -engine -start Djava.io.tmpdir=/opt/cdpdeployment/osgitmp"
==============================================================================
sudo init 6 //to restart
sudo reboot //to restart
shutdown -r now //to reboot

 988  ls
  989  du -sch */ 2> /dev/null
  990  cd /
  991  du -sch */ 2> /dev/null
  992  pidof java | xargs pwdx
  993  tqlstop
  994  pidof java | xargs pwdx
  995  df -h
  996  history
=======================================================================

APIGW only 443 we will remove from load balancer
=======================================================
rm -rf java_pid12770.hprof
tar -cvzf logs1203.tar.gz log/
cp -rp logs1203.tar.gz /tmp/
chmod -644 /tmp/logs1127.tar.gz

scp aws-produs-v4-devengine-vegas-5:/tmp/logs1127.tar.gz ~/desktop/
 scp aws-preprod-v4-data-3:/var/logs0123.tar.gz ~/desktop/

 scp aws-produs-v4-devengine-erie-2:/tmp/extenginelog1127.tar.gz ~/desktop/
pidof java | xargs pwdx
============================================================
8082  DE
8134  Ext
=============================================
systemctl start elasticsearch  //to reatart elastic search
-----------------------------------------------------
Cluster Monitoring :

First need to check which process getting failed by seeing the Cluster Monitoring dashboard

Then login to that VM and check any hprof files there are not.If there is any big hprof file , that we need to delete. before deletion we need to do follwing steps.

--> take logs backup of that particular process(make a copy in local desktop and need to raise CDET ticket(need to send to dev team))

--> Then we need to login to Central monitor machine(one per each reagion )(even here can find ip details where that process in that json file of particular tenant)

--> Stop the monitor process (command : stopmonitor)
--> Pause the cluster in API sciecne monitor dashboard(Need to check with Shaheer)
--> Stop the process using the command : tql -cluster -stop clusterid=Berlin_Cluster,instance=DE_NorthBound
--> Delete the hprof files in that machine
--> Start the process using the command : tql -cluster -start clusterid=Berlin_Cluster,instance=DE_NorthBound
--> Start the Cluster in the API Sceience monitor dashboard(Need to check with Shaheer)
--> Start the monitor the process (Command : startmonitor)

--> primarily we need to anaylyze the log.

Note: stop the cluster command : stopcluster Tenant_name (all the process will be stopped and always check the alias names in bashrc_profile))



 